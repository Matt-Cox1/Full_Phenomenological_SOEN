{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/matthewcox/Documents/UCL/MSc/Full_Phen_SOEN\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "\n",
    "# go up a dir\n",
    "os.chdir(os.path.dirname(os.path.abspath(\"./\")))\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from model.soen_model import SOENModel\n",
    "from model_config_files.two_moons_config import TwoMoonsConfig\n",
    "\n",
    "\n",
    "from utils.soen_model_utils import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equlibrium Propagation Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from model.soen_model import SOENModel\n",
    "from model.model_config import SOENConfig\n",
    "import copy\n",
    "\n",
    "LABELSIZE = 16\n",
    "FONTSIZE = 18\n",
    "\n",
    "class SOENModelEP(SOENModel):\n",
    "    def __init__(self, config: SOENConfig):\n",
    "        super().__init__(config)\n",
    "        self.is_weakly_clamped = False\n",
    "        self.beta = 0.0\n",
    "        self.target = None\n",
    "        self.state_evolution = []\n",
    "        self.learning_rule = \"simple_state\"\n",
    "        self.rule_params = {\n",
    "            \"simple_state\": {\"beta\": 1, \"learning_rate\": 1},\n",
    "            \"simple_flux\": {\"beta\": 1, \"learning_rate\": 1},\n",
    "            \"EqProp\": {\"beta\": 1, \"learning_rate\": 1},\n",
    "            \"EqProp_var1\": {\"beta\": 1, \"learning_rate\": 1},\n",
    "            \"SOEN1\": {\"beta\": 1, \"learning_rate\": 1},\n",
    "        }\n",
    "        self.run_to_equilibrium = config.run_to_equilibrium\n",
    "        self.tol = config.tol\n",
    "\n",
    "    def forward(self, x, y=None, free_steps=100, nudged_steps=20, beta=0.1, initial_state=None):\n",
    "        batch_size = x.shape[0]\n",
    "        if initial_state is None:\n",
    "            s = torch.zeros(batch_size, self.num_total, device=x.device)\n",
    "        else:\n",
    "            s = initial_state.clone()\n",
    "\n",
    "        s[:, :self.num_input] = x  # Clamp input\n",
    "\n",
    "        # Free phase\n",
    "        self.is_weakly_clamped = False\n",
    "        self.beta = 0.0\n",
    "        self.target = None\n",
    "\n",
    "        s, phi = self.run_phase(s, x, free_steps)\n",
    "        free_state = s.clone()\n",
    "        free_phi = phi.clone()\n",
    "\n",
    "        # Nudged phase\n",
    "        self.is_weakly_clamped = True\n",
    "        self.beta = beta\n",
    "        self.target = y\n",
    "\n",
    "        s, phi = self.run_phase(s, x, nudged_steps)\n",
    "        nudged_state = s.clone()\n",
    "        nudged_phi = phi.clone()\n",
    "\n",
    "        return free_state, nudged_state, s[:, -self.num_output:], s, free_phi, nudged_phi\n",
    "\n",
    "    def run_phase(self, s, x, max_steps):\n",
    "        prev_s = s.clone()\n",
    "        for step in range(max_steps):\n",
    "            s, phi = self.step(s, x)\n",
    "            self.state_evolution.append((s.clone(), phi.clone()))\n",
    "            \n",
    "            if self.run_to_equilibrium:\n",
    "                diff = torch.max(torch.abs(s - prev_s))\n",
    "                if diff < self.tol:\n",
    "                    break\n",
    "            prev_s = s.clone()\n",
    "        \n",
    "        return s, phi\n",
    "\n",
    "    def step(self, s, x):\n",
    "        J_masked = self.J * self.mask\n",
    "        phi = torch.mm(s, J_masked.t()) + self.flux_offset\n",
    "\n",
    "        if self.clip_phi:\n",
    "            phi = torch.clamp(phi, -0.5, 0.5)\n",
    "\n",
    "        ds = self.gamma * self.g(phi, s) - s / self.tau\n",
    "\n",
    "        if self.is_weakly_clamped:\n",
    "            output_idx = slice(-self.num_output, None)\n",
    "            ds[:, output_idx] += self.beta * (self.target - s[:, output_idx])\n",
    "\n",
    "        if self.clip_state:\n",
    "            s = torch.clamp(s + self.dt * ds, 0.0, 1)\n",
    "        else:\n",
    "            s = s + self.dt * ds\n",
    "\n",
    "        # Keep input clamped\n",
    "        s[:, :self.num_input] = x\n",
    "\n",
    "        return s, phi\n",
    "\n",
    "    def compute_weight_updates(self, free_state, nudged_state, free_phi, nudged_phi, beta):\n",
    "        dJ = torch.zeros_like(self.J)\n",
    "        params = self.rule_params[self.learning_rule]\n",
    "\n",
    "        for i in range(self.J.shape[0]):\n",
    "            for j in range(self.J.shape[1]):\n",
    "                if self.mask[i, j] != 0:  # Only update existing connections\n",
    "                    if self.learning_rule == \"simple_state\":\n",
    "                        dJ[i, j] = -((nudged_state[0, i] * nudged_state[0, j] - free_state[0, i] * free_state[0, j])) / beta\n",
    "                    elif self.learning_rule == \"simple_flux\":\n",
    "                        dJ[i, j] = -((nudged_phi[0, i] * nudged_phi[0, j] - nudged_phi[0, i] * nudged_phi[0, j])) / beta\n",
    "                    elif self.learning_rule == \"EqProp\":\n",
    "                        dJ[i, j] = -((self.gamma[i]/ beta) * (self.g(nudged_phi[0, i], nudged_state[0, i]) * self.g(nudged_phi[0, j], nudged_state[0, j]) -\n",
    "                                                      self.g(free_phi[0, i], free_state[0, i]) * self.g(nudged_phi[0, j], free_state[0, j]))) \n",
    "                    elif self.learning_rule == \"EqProp_var1\":\n",
    "                        dJ[i, j] = -((self.gamma[i]/ beta) * (self.g(nudged_phi[0, j], nudged_state[0, i]) * self.g(nudged_phi[0, j], nudged_state[0, i]) -\n",
    "                                                      self.g(free_phi[0, j], free_state[0, i]) * self.g(free_phi[0, j], free_state[0, i]))) \n",
    "                    elif self.learning_rule == \"SOEN1\":\n",
    "                        dJ[i, j] = -(self.gamma[i]/ beta) * (self.g(nudged_phi[0, i], nudged_state[0, i]) * nudged_state[0, j] -\n",
    "                                                      self.g(free_phi[0, i], free_state[0, i]) * free_state[0, j]) \n",
    "\n",
    "        return dJ\n",
    "\n",
    "    def update_weights(self, dJ):\n",
    "        learning_rate = self.rule_params[self.learning_rule][\"learning_rate\"]\n",
    "        with torch.no_grad():\n",
    "            self.J.add_(learning_rate * dJ)\n",
    "        self.J.data *= self.mask  # Ensure masked weights remain zero\n",
    "\n",
    "    def set_learning_rule(self, rule):\n",
    "        valid_rules = list(self.rule_params.keys())\n",
    "        if rule in valid_rules:\n",
    "            self.learning_rule = rule\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown learning rule: {rule}. Valid rules are: {', '.join(valid_rules)}\")\n",
    "\n",
    "\n",
    "def run_experiment(original_model, x, y, free_steps, nudged_steps, num_iterations, rule):\n",
    "    model = copy.deepcopy(original_model)\n",
    "    model.set_learning_rule(rule)\n",
    "    current_state = None\n",
    "    model.state_evolution = []\n",
    "    mse_history = []\n",
    "\n",
    "    for iteration in range(num_iterations):\n",
    "        free_state, nudged_state, final_output, current_state, free_phi, nudged_phi = model(\n",
    "            x, y, \n",
    "            free_steps=free_steps, \n",
    "            nudged_steps=nudged_steps, \n",
    "            beta=model.rule_params[rule].get(\"beta\"),\n",
    "            initial_state=current_state\n",
    "        )\n",
    "\n",
    "        dJ = model.compute_weight_updates(free_state, nudged_state, free_phi, nudged_phi, model.rule_params[rule].get(\"beta\", 0.1))\n",
    "        model.update_weights(dJ)\n",
    "\n",
    "        mse = nn.MSELoss()(final_output, y).item()\n",
    "        mse_history.append(mse)\n",
    "\n",
    "    return mse_history\n",
    "\n",
    "def save_results_to_csv(results, filename):\n",
    "    with open(filename, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        header = ['Run', 'Rule', 'Iteration', 'MSE']\n",
    "        writer.writerow(header)\n",
    "\n",
    "        for run, run_results in enumerate(results):\n",
    "            for rule, mse_history in run_results.items():\n",
    "                for iteration, mse in enumerate(mse_history):\n",
    "                    writer.writerow([run + 1, rule, iteration + 1, mse])\n",
    "\n",
    "def plot_combined_mse(results, save_path):\n",
    "    plt.figure(figsize=(12, 8), dpi=300)\n",
    "    \n",
    "    for rule in results[0].keys():\n",
    "        rule_data = np.array([run_results[rule] for run_results in results])\n",
    "        mean = np.mean(rule_data, axis=0)\n",
    "        std = np.std(rule_data, axis=0)\n",
    "        \n",
    "        x = range(1, len(mean) + 1)\n",
    "        plt.plot(x, mean, label=rule, linewidth=2)\n",
    "        plt.fill_between(x, mean - std, mean + std, alpha=0.3)\n",
    "\n",
    "    plt.xlabel('Iteration', fontsize=FONTSIZE)\n",
    "    plt.ylabel('Mean Squared Error', fontsize=FONTSIZE)\n",
    "    plt.yscale('log')\n",
    "    plt.legend(fontsize=LABELSIZE)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=LABELSIZE)\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_path, \"combined_mse_plot.png\"))\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    x = torch.tensor([[0.5]])\n",
    "    y = torch.tensor([[0.05]])\n",
    "\n",
    "    config = SOENConfig(\n",
    "        num_input=1,\n",
    "        num_hidden=10,\n",
    "        num_output=1,\n",
    "        p_input_hidden=1.0,\n",
    "        p_hidden_output=1.0,\n",
    "        p_input_input=1.0,\n",
    "        p_hidden_hidden=1.0,\n",
    "        p_output_output=1.0,\n",
    "        allow_self_connections=False,\n",
    "        allow_output_to_hidden_feedback=True,\n",
    "        allow_hidden_to_input_feedback=True,\n",
    "        allow_skip_connections=False,\n",
    "        p_skip_connections=1.0,\n",
    "        activation_function=\"NN_dendrite\",\n",
    "        dt=0.05,\n",
    "        max_iter=1000,\n",
    "        run_to_equilibrium=True,\n",
    "        tol=1e-6,\n",
    "        clip_phi=True, \n",
    "        clip_state=True,\n",
    "        test_noise_std=0.05,\n",
    "        bias_flux_offsets=True,\n",
    "        enforce_symmetric_weights=True,\n",
    "        weight_init_method=\"glorot\",\n",
    "        # init_scale=0.5,\n",
    "    )\n",
    "\n",
    "    free_steps = 200\n",
    "    nudged_steps = 200\n",
    "    num_iterations = 100\n",
    "    num_runs = 1\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        print(f\"\\nRun {run + 1}/{num_runs}\")\n",
    "        original_model = SOENModelEP(config)\n",
    "        original_model.eval()\n",
    "\n",
    "        run_results = {}\n",
    "        for rule in original_model.rule_params.keys():\n",
    "            print(f\"  Training with {rule} learning rule\")\n",
    "            run_results[rule] = run_experiment(original_model, x, y, free_steps, nudged_steps, num_iterations, rule)\n",
    "\n",
    "        results.append(run_results)\n",
    "\n",
    "    save_path = \"/Users/matthewcox/Documents/UCL/MSc/Training_Apps/Results/ep\"\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    csv_filename = os.path.join(save_path, \"mse_results.csv\")\n",
    "    save_results_to_csv(results, csv_filename)\n",
    "    print(f\"Results saved to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
